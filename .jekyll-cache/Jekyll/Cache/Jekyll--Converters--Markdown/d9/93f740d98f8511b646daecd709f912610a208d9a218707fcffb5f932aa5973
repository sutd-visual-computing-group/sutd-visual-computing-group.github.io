I"†<h1 id="publications">Publications</h1>

<h2 id="group-highlights">Group highlights</h2>

<p>For a full list of publications go to <a href="https://scholar.google.com/citations?hl=en&amp;user=vJQArFkAAAAJ">Google Scholar</a></p>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection</pubtit>
      <p><img src="/images/pubpic/cnn-generated-images.jpg" class="img-responsive" width="40%" height="40%" style="float: left" /></p>
      <p>CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to near-perfect accuracy across multiple state-of-the art GAN models. In our work, we investigate the validity of assertions claiming that CNN-generated images are unable to achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent CNN-generated images emerging from our handcrafted experiments where we empirically show that this frequency discrepancy can be avoided by a minor architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection. Through our study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative modelsâ€”contrary to the belief of some existing workâ€”, and such features are not robust to perform synthetic image detection.</p>
      <p><em>Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Ngai-Man Cheung</em></p>
      <p><strong><a href="https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/">CVPR-2021 (Oral). Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</a></strong></p>
      <p class="text-danger"><strong> </strong></p>
      <p> </p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>On Data Augmentation for GAN training</pubtit>
      <p><img src="/images/pubpic/dag.jpg" class="img-responsive" width="40%" height="40%" style="float: left" /></p>
      <p>Recent successes in Generative Adversarial Networks (GAN) have affirmed the importance of using more data in GAN training. Yet it is expensive to collect data in many domains such as medical applications. Data Augmentation (DA) has been applied in these applications. In this work, we first argue that the classical DA approach could mislead the generator to learn the distribution of the augmented data, which could be different from that of the original data. We then propose a principled framework, termed Data Augmentation Optimized for GAN (DAG), to enable the use of augmented data in GAN training to improve the learning of the original distribution. We provide theoretical analysis to show that using our proposed DAG aligns with the original GAN in minimizing the Jensenâ€“Shannon (JS) divergence between the original distribution and model distribution. Importantly, the proposed DAG effectively leverages the augmented data to improve the learning of discriminator and generator. We conduct experiments to apply DAG to different GAN models: unconditional GAN, conditional GAN, self-supervised GAN and CycleGAN using datasets of natural images and medical images. The results show that DAG achieves consistent and considerable improvements across these models. Furthermore, when DAG is used in some GAN models, the system establishes state-of-the-art Frechet Inception Distance (FID) scores. Our code is available.</p>
      <p><em>Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen, Ngai-Man Cheung</em></p>
      <p><strong><a href="">IEEE Transactions on Image Processing</a></strong></p>
      <p class="text-danger"><strong> </strong></p>
      <p> </p>
    </div>
  </div>

</div>

<p> Â  </p>

<h2 id="2021">2021</h2>

<p>Shell Theory: A Statistical Model of Reality <br />
  <em>Daniel Lin, Siying Liu, Hongdong Li, Ngai-Man Cheung, Changhao Ren, Yasuyuki Matsushita </em><br /><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444188">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></p>

<p>Joint estimation of low-rank components and connectivity graph in high-dimensional graph signals: Application to brain imaging <br />
  <em>Rui Liu, Ngai-Man Cheung </em><br /><a href="https://www.sciencedirect.com/science/article/pii/S0165168420304758">Signal Processing</a></p>

<p>A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection <br />
  <em>Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Ngai-Man Cheung </em><br /><a href="https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/">CVPR-2021 (Oral). Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</a></p>

<p>On Data Augmentation for GAN training <br />
  <em>Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen, Ngai-Man Cheung </em><br /><a href="">IEEE Transactions on Image Processing</a></p>

:ET