- title: Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning
  image: neurips21-thumbnail.jpg
  description: Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing 
              its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use 
              of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. 
              In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on 
              a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. 
              The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no 
              deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to 
              multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. 
              Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by 
              hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner 
              that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts 
              to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML
  authors: Milad Abdollahzadeh, Touba Malekzadeh, Ngai-Man Cheung
  link:
    url: https://miladabd.github.io/KML/
    display:  Advances in Neural Information Processing Systems 35 Proceedings (NeurIPS 2021)
  highlight: 1
  news2:

- title: Shell Theory&#58; A Statistical Model of Reality
  image: TBG_SL.png
  description:
  authors: Daniel Lin, Siying Liu, Hongdong Li, Ngai-Man Cheung, Changhao Ren, Yasuyuki Matsushita
  link:
    url: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444188
    display:  IEEE Transactions on Pattern Analysis and Machine Intelligence
  highlight: 0
  news2:

- title: "Joint estimation of low-rank components and connectivity graph in high-dimensional graph signals: Application to brain imaging"
  image: TiNHigh.png
  description: 
  authors: Rui Liu, Ngai-Man Cheung
  link:
    url: https://www.sciencedirect.com/science/article/pii/S0165168420304758
    display: Signal Processing
  highlight: 0

- title: "A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection"
  image: cnn-generated-images.jpg
  description: CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. 
                Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. 
                Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to near-perfect accuracy 
                across multiple state-of-the art GAN models. In our work, we investigate the validity of assertions claiming that CNN-generated images are unable to 
                achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent 
                CNN-generated images emerging from our handcrafted experiments where we empirically show that this frequency discrepancy can be avoided by a minor 
                architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently 
                proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection. 
                Through our study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative 
                models—contrary to the belief of some existing work—, and such features are not robust to perform synthetic image detection. 
  authors: Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Ngai-Man Cheung
  link:
    url: https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/
    display: CVPR-2021 (Oral). Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
  highlight: 1

- title: "On Data Augmentation for GAN training"
  image: dag.jpg
  description: Recent successes in Generative Adversarial Networks (GAN) have affirmed the importance of using more data in GAN training. 
                Yet it is expensive to collect data in many domains such as medical applications. Data Augmentation (DA)
                has been applied in these applications. In this work, we first
                argue that the classical DA approach could mislead the generator
                to learn the distribution of the augmented data, which could
                be different from that of the original data. We then propose
                a principled framework, termed Data Augmentation Optimized
                for GAN (DAG), to enable the use of augmented data in GAN
                training to improve the learning of the original distribution. We
                provide theoretical analysis to show that using our proposed DAG
                aligns with the original GAN in minimizing the Jensen–Shannon
                (JS) divergence between the original distribution and model
                distribution. Importantly, the proposed DAG effectively leverages
                the augmented data to improve the learning of discriminator and generator. We conduct experiments to apply DAG to
                different GAN models&#58; unconditional GAN, conditional GAN,
                self-supervised GAN and CycleGAN using datasets of natural
                images and medical images. The results show that DAG achieves
                consistent and considerable improvements across these models.
                Furthermore, when DAG is used in some GAN models, the
                system establishes state-of-the-art Frechet Inception Distance 
                (FID) scores. Our code is available.
  authors: Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen, Ngai-Man Cheung
  link:
    url: 
    display: IEEE Transactions on Image Processing
  highlight: 0
